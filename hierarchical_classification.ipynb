{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "Build a Deep Learning classification model that takes the hierarchy into consideration.\n",
    "Take any 4 categories from the dataset (100 images each) such that there is a hierarchical relationship between them for eg:\n",
    "\n",
    "Animals\n",
    "- Dog\n",
    "- Cat\n",
    "\n",
    "~~Flowers~~ Fruits\n",
    "- ~~Rose~~ Grapes\n",
    "- ~~Sunflower~~ Pear\n",
    "\n",
    "Build a Classification model for the above 4 categories, such that the penalty of inter-category prediction is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:34:14.129359Z",
     "start_time": "2019-07-16T05:34:10.445395Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "from textwrap import wrap\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras import layers as L\n",
    "from keras import optimizers as opt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for reproducibility\n",
    "from numpy.random import seed\n",
    "seed(41)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T10:36:46.332600Z",
     "start_time": "2019-07-15T10:36:46.330594Z"
    }
   },
   "source": [
    "## Extract and save the image files (28x28) from .npy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not run next __two__ code cell. Data has already been prepared and kept in folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the npy file and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:51:33.847612Z",
     "start_time": "2019-07-15T11:51:32.753433Z"
    }
   },
   "outputs": [],
   "source": [
    "# WARNING: this cell needed to run only once. After downloading the npy files\n",
    "\n",
    "# used code from: https://github.com/C-Aniruddh/RapidDraw/blob/in-dev/processing/process_all.py\n",
    "number_images = 100; # Number of images in each category\n",
    "img_width, img_height = 28, 28\n",
    "\n",
    "\n",
    "npy_dir = '../data_dump/'\n",
    "out_dir = './data/'\n",
    "npy_files = [f for f in os.listdir(npy_dir) if os.path.isfile(os.path.join(npy_dir, f))]\n",
    "print('Available classes:')\n",
    "print(npy_files)\n",
    "\n",
    "categories = []\n",
    "\n",
    "for x in npy_files:\n",
    "    category_split = x.split('.')\n",
    "    category = category_split[0]\n",
    "    categories.append(category)\n",
    "    \n",
    "print('Data from following classes will be unpacked:')\n",
    "print(categories)\n",
    "\n",
    "for y in categories:\n",
    "    if not os.path.exists(os.path.join(out_dir, y)):\n",
    "        os.makedirs(os.path.join(out_dir, y))\n",
    "\n",
    "index_cat = 0\n",
    "for z in npy_files:\n",
    "    print('Processing file', z)\n",
    "    images = np.load(os.path.join(npy_dir, z))\n",
    "    print('Saving in', categories[index_cat])\n",
    "    number_imgs = range(0, number_images, 1)\n",
    "    for a in number_imgs:\n",
    "        print('\\t Processing Image', a+1)\n",
    "        file_name = '%s.jpg' % (a+1)\n",
    "        file_path = os.path.join(out_dir, categories[index_cat], file_name)\n",
    "        img = images[a].reshape(img_width, img_height)\n",
    "        f_img = Image.fromarray(img)\n",
    "        inverted_image = PIL.ImageOps.invert(f_img)\n",
    "        inverted_image.save(file_path, 'JPEG')\n",
    "    index_cat = index_cat + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look at few training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:35:40.685549Z",
     "start_time": "2019-07-16T05:35:40.355970Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomly picks 4 images per class\n",
    "r, c = 2, 2\n",
    "for d in os.listdir(out_dir):\n",
    "    print(d)\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 1\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            img = plt.imread(out_dir+d+'/'+str(random.randint(1, 100))+'.jpg')\n",
    "            axs[i, j].imshow(img, cmap=cm.gray)\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T04:48:51.019704Z",
     "start_time": "2019-07-16T04:48:51.017700Z"
    }
   },
   "source": [
    "## Highlevel idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use a neural network to build the classifier. The reason is two-fold:\n",
    "- CNN based neural networks are historically proven to be very strong at image classification, identification tasks.\n",
    "- The test is on Deep Learning! ;-)\n",
    "\n",
    "So, My idea is to build a multi-task model. First it will try to classify images into $animal$ or $fruit$ classes and then it will further classify among the four classes ($dog$, $cat$, $grapes$, $pear$).\n",
    "The reason behind using a multi-task model is \n",
    "- I can use different loss weights for different tasks. A higher weight for animal vs fruit classification loss and a comparatively lower weight to 4 class classification loss.\n",
    "- This particular model construction captures the hierarchical nature of the problem nicely.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulled out first 100 samples from each class for training and next 100 from each class for validation/testing.\n",
    "The test data is completely unseen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and verify the data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why I need a generator when $4*100*(28*28) = 1.2MB$ would fit nicely in computer memory?\n",
    "- It is good to be prepare a pipeline which can handle large size data\n",
    "- To show off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:37:12.207981Z",
     "start_time": "2019-07-16T05:37:12.204975Z"
    }
   },
   "outputs": [],
   "source": [
    "# few constants\n",
    "data_path = './data/'\n",
    "val_data_path = './val_data/'\n",
    "img_width, img_height, n_channel = 28, 28, 3\n",
    "img_shape = (img_width, img_height)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:37:13.125337Z",
     "start_time": "2019-07-16T05:37:12.907718Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "train_generator = datagen.flow_from_directory(data_path, target_size=(img_width, img_height)\n",
    "                    , class_mode='categorical'\n",
    "                    , batch_size=batch_size, interpolation='nearest'\n",
    "                    , shuffle=True\n",
    "                   )\n",
    "val_generator = ImageDataGenerator(\n",
    "    rescale=1./255).flow_from_directory(val_data_path, target_size=(img_width, img_height)\n",
    "                    , class_mode='categorical'\n",
    "                    , batch_size=batch_size, interpolation='nearest'\n",
    "                    , shuffle=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I need the below generator?\n",
    "- The $train\\_generator$ or $val\\_generator$ created above produces target for 4 class classification problem. But our $animal vs fruit$ classification needs a different target for the same batch. Please see the inline comments inside the below functions for details about each type of targets.\n",
    "- Wrapping the generators to produce X_batch, animal vs fruit target and 4 class classification target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:37:39.233917Z",
     "start_time": "2019-07-16T05:37:39.228873Z"
    }
   },
   "outputs": [],
   "source": [
    "# mode will be train for both training and validation\n",
    "def combined_generator(datagen, mode='train'):\n",
    "    y_4c = None\n",
    "    while True:\n",
    "        if mode == 'train':\n",
    "            X_batch, y_4c = datagen.next() # produces 4 class classification target\n",
    "        else:\n",
    "            X_batch = datagen.next()\n",
    "        if y_4c is not None:\n",
    "            # class and how the target looks for y_4c\n",
    "            # cat     [1, 0, 0, 0]\n",
    "            # dog     [0, 1, 0, 0]\n",
    "            # grapes  [0, 0, 1, 0]\n",
    "            # pear    [0, 0, 0, 1]\n",
    "\n",
    "            # for a_vs_f model we need target of shape (batch_size, 2)\n",
    "            # class cat and dog -> [1, 0]\n",
    "            # class grapes and pear -> [0, 1]\n",
    "            # how class and the target should look for a_vs_f model\n",
    "            # cat     [1, 0]\n",
    "            # dog     [1, 0]\n",
    "            # grapes  [0, 1]\n",
    "            # pear    [0, 1]\n",
    "\n",
    "            y_a_f = np.zeros((y_4c.shape[0], 2))\n",
    "            for idx, y in enumerate(y_4c):\n",
    "                if np.all(y == [1, 0, 0, 0]) or np.all(y == [0, 1, 0, 0]):\n",
    "                    y_a_f[idx] = [1, 0]\n",
    "                else:\n",
    "                    y_a_f[idx] = [0, 1]\n",
    "            # produce animal vs fruit and 4class classification target for the sasme set of training images\n",
    "            yield X_batch, [y_a_f, y_4c]\n",
    "        else:\n",
    "            yield X_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:37:43.634046Z",
     "start_time": "2019-07-16T05:37:42.916059Z"
    }
   },
   "outputs": [],
   "source": [
    "# test how my generator is doing\n",
    "X, y = next(combined_generator(train_generator)) # ask for a batch\n",
    "\n",
    "print('Shape of one batch of data:')\n",
    "print('X shape: ', X.shape)\n",
    "print('y_a_f shape: ', y[0].shape)\n",
    "print('y_4c shape: ', y[1].shape)\n",
    "\n",
    "\n",
    "r, c = 4, 4 # lets not show entire batch, check rxc images\n",
    "imgs = X[:r*c]\n",
    "label1 = y[0][:r*c] # animal vs fruit target. see the generator ouput order\n",
    "label2 = y[1][:r*c] # 4 class classification output. see the generator ouput order\n",
    "\n",
    "cnt = 0\n",
    "fig, axs = plt.subplots(r, c)\n",
    "fig.tight_layout()\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        img = imgs[cnt]\n",
    "        axs[i, j].imshow(img, cmap=cm.gray)\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].set_title('\\n'.join(wrap(str(label1[cnt])+str(label2[cnt]),60))) # took some time to figure this out!\n",
    "        cnt += 1\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:37:52.907389Z",
     "start_time": "2019-07-16T05:37:52.905387Z"
    }
   },
   "outputs": [],
   "source": [
    "# some model realted constants\n",
    "latent_dim = 128\n",
    "epochs = 50\n",
    "learning_rate = 1E-4 # with only 100 samples per class, slow cooking (small batch_size, small lr) seems good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:42:00.291547Z",
     "start_time": "2019-07-16T05:42:00.285028Z"
    }
   },
   "outputs": [],
   "source": [
    "# build the animal vs fruit model\n",
    "def build_a_vs_f_model(input_dim=(img_width, img_height, n_channel), n_classes=2):\n",
    "    input_ = L.Input(shape=input_dim)\n",
    "    x = L.Conv2D(32, kernel_size=(3, 3), activation='relu')(input_)\n",
    "    x = L.Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = L.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = L.Dropout(0.25)(x)\n",
    "    x = L.Flatten()(x)\n",
    "    feat = L.Dense(latent_dim, activation='relu')(x)\n",
    "    pred = L.Dense(n_classes, activation='softmax')(feat)\n",
    "\n",
    "    # this is to classify animal vs fruit\n",
    "    af_model = keras.models.Model(inputs=input_, outputs=pred, name='af_model')\n",
    "    # idea is to use this layer output as a input feature to the 4 class classification problem\n",
    "    af_feature_model = keras.models.Model(inputs=input_, outputs=feat, name='feat_model')\n",
    "    \n",
    "    af_model.summary()\n",
    "    keras.utils.vis_utils.plot_model(af_model, to_file='a_vs_f_model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    return af_model, af_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:42:00.897238Z",
     "start_time": "2019-07-16T05:42:00.890156Z"
    }
   },
   "outputs": [],
   "source": [
    "# build the 4 class classification model\n",
    "def build_4class_model(input_dim=(img_width, img_height, n_channel), n_classes=4, latent_dim=128):\n",
    "    input_img = L.Input(shape=input_dim)\n",
    "    x = L.Conv2D(32, kernel_size=(3, 3), activation='relu')(input_img)\n",
    "    x = L.Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = L.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = L.Dropout(0.25)(x)\n",
    "    x = L.Flatten()(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    \n",
    "    input_feat = L.Input(shape=(latent_dim,))\n",
    "    y = L.Concatenate()([x, input_feat])\n",
    "    y = L.Dense(128)(y)\n",
    "    y = L.Dropout(0.25)(y)\n",
    "    y = L.Dense(64)(y)\n",
    "    y = L.Dropout(0.25)(y)\n",
    "    y = L.Dense(32)(y)\n",
    "    y = L.Dropout(0.25)(y)\n",
    "    pred = L.Dense(n_classes, activation='softmax')(y)\n",
    "    model = keras.models.Model(inputs=[input_img, input_feat], outputs=pred, name='class4_model')\n",
    "    model.summary()\n",
    "    keras.utils.vis_utils.plot_model(model, to_file='class4_model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:42:01.487351Z",
     "start_time": "2019-07-16T05:42:01.483341Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_combined_model(a_vs_f_model, feat_model, class4_model):\n",
    "    inputs = L.Input(shape=(img_width, img_height, n_channel))\n",
    "    a_f = a_vs_f_model(inputs)\n",
    "    feat = feat_model(inputs)\n",
    "    pred = class4_model([inputs, feat])\n",
    "    model = keras.models.Model(inputs=inputs, outputs=[a_f, pred], name='comb_model')\n",
    "    model.summary()\n",
    "    keras.utils.vis_utils.plot_model(model, to_file='comb_model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:42:02.105255Z",
     "start_time": "2019-07-16T05:42:02.099238Z"
    }
   },
   "outputs": [],
   "source": [
    "# now, time to train the model\n",
    "def train_model():\n",
    "    \n",
    "    # create models\n",
    "    a_vs_f_model, feat_model = build_a_vs_f_model()\n",
    "    class_4_model = build_4class_model()\n",
    "    combined_model = build_combined_model(a_vs_f_model, feat_model, class_4_model)\n",
    "    \n",
    "    # get opt\n",
    "    comb_opt = opt.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    loss_weights = [2, 1] # animal vs fruit classification is given more weight\n",
    "    combined_model.compile(optimizer=comb_opt\n",
    "                           , loss=['categorical_crossentropy', 'categorical_crossentropy']\n",
    "                           , loss_weights=loss_weights, metrics=['acc'])\n",
    "    \n",
    "    # set up callbacks\n",
    "    model_filepath = 'model.hdf5'\n",
    "    chkpoint = keras.callbacks.ModelCheckpoint(model_filepath, monitor='val_loss', verbose=1\n",
    "                    , save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    callback_list=[keras.callbacks.History(), chkpoint]\n",
    "    \n",
    "    history = combined_model.fit_generator(\n",
    "            generator=combined_generator(train_generator),\n",
    "            steps_per_epoch=1+train_generator.n//train_generator.batch_size,\n",
    "            validation_data=combined_generator(val_generator),\n",
    "            validation_steps=1+val_generator.n//val_generator.batch_size,\n",
    "            callbacks=callback_list,\n",
    "            epochs=epochs\n",
    "        )\n",
    "        \n",
    "    return combined_model, history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:45:12.250239Z",
     "start_time": "2019-07-16T05:42:02.723105Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_model, history = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:45:12.263270Z",
     "start_time": "2019-07-16T05:45:12.253246Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets have a look at the loss and acc of the model for train and val dataset\n",
    "def plot_model_perf(history):\n",
    "    # keys are hard to remmeber\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    # summarize history for different accuracies\n",
    "    plt.plot(history.history['af_model_acc'])\n",
    "    plt.plot(history.history['val_af_model_acc'])\n",
    "    plt.title('animal vs fruit model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['class4_model_acc'])\n",
    "    plt.plot(history.history['val_class4_model_acc'])\n",
    "    plt.title('4 class model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for losses\n",
    "    plt.plot(history.history['af_model_loss'])\n",
    "    plt.plot(history.history['val_af_model_loss'])\n",
    "    plt.title('animal vs fruit model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['class4_model_loss'])\n",
    "    plt.plot(history.history['val_class4_model_loss'])\n",
    "    plt.title('4 class model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T05:45:12.754270Z",
     "start_time": "2019-07-16T05:45:12.266276Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_perf(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### animal vs fruit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"files/a_vs_f_model_plot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4 class classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"files/class4_model_plot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Combined model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"files/comb_model_plot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Try training animal vs fruit model first, then freeze it and train the comnbined model.\n",
    "2. Playt with learning rate scheduling. Suppose 1E-4 is my base lr. Linearly increase lr from 1E-6 to 1E-4 over a period of 10 epochs (idea is to not take any catastrophic step while the model wights are still random), then hold the base rate for 30 epochs and finally bring it linearly down to 0 (idea is to take as small steps as possible when the model is stabilised).\n",
    "3. Add more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
